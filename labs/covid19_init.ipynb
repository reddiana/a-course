{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers, models, layers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import ResponseError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading images...\")\n",
    "\n",
    "minioClient = Minio(\n",
    "                'minio-service.kubeflow:9000',\n",
    "                access_key='minio', \n",
    "                secret_key='minio123', \n",
    "                secure=False\n",
    "            )\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# read all X-Rays in the specified path, and resize them all to 256x256\n",
    "\n",
    "for i in minioClient.list_objects('dataset', prefix='covid19', recursive=True):\n",
    "    label = i.object_name.split(os.path.sep)[-2]\n",
    "    minioObj = minioClient.get_object('dataset', i.object_name)\n",
    "    byteArray = minioObj.read()\n",
    "    pil_image = Image.open(io.BytesIO(byteArray)).convert('RGB')\n",
    "    image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ...  227 images loaded in 3x classes:\n",
      "['covid' 'normal' 'pneumonia_bac']\n"
     ]
    }
   ],
   "source": [
    "#normalise pixel values to real numbers between 0.0 - 1.0 \n",
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding for a 3-class labeling \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "labels = to_categorical(integer_encoded)\n",
    "\n",
    "print(\"... ... \", len(data), \"images loaded in 3x classes:\")\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val, y_train, y_val) = train_test_split(data, labels, test_size=0.20, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "LEARNING_RATE = 0.00001 # List: 0.001, 0.0001, 0.0003, 0.00001, 0.00003\n",
    "DENSE = 128             # Range: 50-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Model)           (None, 8, 8, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16777344  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 40,367,235\n",
      "Trainable params: 16,798,339\n",
      "Non-trainable params: 23,568,896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "adam_s = Adam(learning_rate = LEARNING_RATE)\n",
    "\n",
    "#model.add(VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet', pooling='average'))\n",
    "model.add(ResNet50V2(input_shape=(256, 256, 3),include_top=False, weights='imagenet',pooling='average'))\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(DENSE, activation='relu'))\n",
    "model.add(Dense(DENSE, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam_s, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the full stack model...\n",
      "Train on 181 samples, validate on 46 samples\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 23s 126ms/sample - loss: 0.9915 - accuracy: 0.5304 - val_loss: 2.2571 - val_accuracy: 0.4783\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 18s 101ms/sample - loss: 0.3583 - accuracy: 0.9282 - val_loss: 2.0100 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 18s 101ms/sample - loss: 0.1814 - accuracy: 0.9613 - val_loss: 1.8047 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 18s 100ms/sample - loss: 0.0962 - accuracy: 0.9834 - val_loss: 1.6902 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 18s 98ms/sample - loss: 0.0567 - accuracy: 0.9945 - val_loss: 1.5254 - val_accuracy: 0.5217\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 18s 99ms/sample - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.3731 - val_accuracy: 0.5435\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 18s 100ms/sample - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.2547 - val_accuracy: 0.5435\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 18s 101ms/sample - loss: 0.0288 - accuracy: 0.9945 - val_loss: 1.1733 - val_accuracy: 0.5435\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 19s 103ms/sample - loss: 0.0290 - accuracy: 0.9890 - val_loss: 1.0552 - val_accuracy: 0.5652\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 20s 111ms/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.9021 - val_accuracy: 0.6087\n"
     ]
    }
   ],
   "source": [
    "# train the head of the network\n",
    "print(\"Training the full stack model...\")\n",
    "hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val), batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9914584709794482, 0.3583354628053159, 0.18142210107646595, 0.09615029909169476, 0.05673937105383333, 0.02498048123033995, 0.02861547686200774, 0.028770578037227056, 0.028960827491066075, 0.014913436076835374]\n",
      "[0.53038675, 0.9281768, 0.96132594, 0.98342544, 0.9944751, 1.0, 1.0, 0.9944751, 0.98895025, 1.0]\n",
      "[2.257123651711837, 2.00996020047561, 1.8046698311100835, 1.690222548401874, 1.525419815726902, 1.3730757806612097, 1.2547043354614922, 1.1733226413312166, 1.055233737696772, 0.902104377746582]\n",
      "[0.47826087, 0.5, 0.5, 0.5, 0.5217391, 0.54347825, 0.54347825, 0.54347825, 0.5652174, 0.6086956]\n"
     ]
    }
   ],
   "source": [
    "loss         = hist.history['loss']\n",
    "accuracy     = hist.history['accuracy']\n",
    "val_loss     = hist.history['val_loss']\n",
    "val_accuracy = hist.history['val_accuracy']\n",
    "\n",
    "print(loss        )\n",
    "print(accuracy    )\n",
    "print(val_loss    )\n",
    "print(val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: s3://model/new-covid/1/assets\n"
     ]
    }
   ],
   "source": [
    "os.environ.update({\n",
    "    'S3_ENDPOINT'          : 'minio-service.kubeflow:9000',\n",
    "    'AWS_ACCESS_KEY_ID'    : 'minio',\n",
    "    'AWS_SECRET_ACCESS_KEY': 'minio123',\n",
    "    'S3_USE_HTTPS'         : '0',   # Whether or not to use HTTPS. Disable with 0.                        \n",
    "    'S3_VERIFY_SSL'        : '0'    # If HTTPS is used, controls if SSL should be enabled. Disable with 0.\n",
    "})  \n",
    "\n",
    "model.save(\"s3://model/new-covid/1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "reddiana/jupyterlab-kale:latest",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
