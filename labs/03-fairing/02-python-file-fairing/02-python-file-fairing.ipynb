{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 201206 10:57:02 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.base.BasePreProcessor object at 0x7f2d342e3400>\n",
      "[I 201206 10:57:02 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f2d342e34a8>\n",
      "[I 201206 10:57:02 config:138] Using deployer: <kubeflow.fairing.deployers.job.job.Job object at 0x7f2d342e3438>\n",
      "[W 201206 10:57:02 append:50] Building image using Append builder...\n",
      "[I 201206 10:57:02 base:107] Creating docker context: /tmp/fairing_context_1eiatjww\n",
      "[I 201206 10:57:02 docker_creds_:234] Loading Docker credentials for repository 'kubeflow-registry.default.svc.cluster.local:30000/kf-base:latest'\n",
      "[W 201206 10:57:02 append:54] Image successfully built in 0.05838843001401983s.\n",
      "[W 201206 10:57:02 append:94] Pushing image kubeflow-registry.default.svc.cluster.local:30000/my-02-python-file-fairing:ABE4CCCB...\n",
      "[I 201206 10:57:02 docker_creds_:234] Loading Docker credentials for repository 'kubeflow-registry.default.svc.cluster.local:30000/my-02-python-file-fairing:ABE4CCCB'\n",
      "[W 201206 10:57:02 append:81] Uploading kubeflow-registry.default.svc.cluster.local:30000/my-02-python-file-fairing:ABE4CCCB\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:107f0b841886b4e032a6ced874db81b71dcdc5e6827b6c0d195defe4c6e661da exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:dccb0709d7fb37e513a933c3848be077f0e514e41a084bd9f3f27dcde169ae20 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:2746a4a261c9e18bfd7ff0429c18fd7522acc14fa4c7ec8ab37ba5ebaadbc584 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:c8e37668deea784f47c8726d934adc12b8d20a2b1c50b0b0c18cb62771cd3684 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:4c1d20cdee96111c8acf1858b62655a37ce81ae48648993542b7ac363ac5c0e5 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:d9a52b85555ed6ba2ba18dcca845679698c740690baca485ab19915a3cdb9dc8 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:75c61371a2e390c1d05234b28163580c90c2e26c6d245984a4da73f9f022c102 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:edc69fe5c6be6938f490e5f91cdb6369799b4a509fd72c292e0cd6fdb3c345b3 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:e52cad4ccd832fc331516c5a5632fdd08c37d711ff243c7e04d6e8c374b9c474 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:40b7934f9a363bd6c48424bcc8c255af7b0ec040f076e030c46f7a03b786c73f exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:0d3160e1d0de4061b5b32ee09af687b898921d36ed9556df5910ddc3104449cd exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:688ae954070df73ce918d07edb7eea7884f407c97137b9b94f16c37a3695d6d1 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:e97116da5f9876a95d0d3f0fd1e3bcc48721f9ac6351ce23aaa3d261b4f9b0d6 exists, skipping\n",
      "[I 201206 10:57:02 docker_session_:280] Layer sha256:8592f093fc78e0d933851ed625592627241c475dd46adad77f37dec9cc867446 exists, skipping\n",
      "[I 201206 10:57:10 docker_session_:284] Layer sha256:910452d16c859be65d14d9d0f977056969dd4b63ece5d930b19cf64f3a32e85a pushed.\n",
      "[I 201206 10:57:14 docker_session_:334] Finished upload of: kubeflow-registry.default.svc.cluster.local:30000/my-02-python-file-fairing:ABE4CCCB\n",
      "[W 201206 10:57:14 append:99] Pushed image kubeflow-registry.default.svc.cluster.local:30000/my-02-python-file-fairing:ABE4CCCB in 12.155272542993771s.\n",
      "[W 201206 10:57:14 job:101] The job fairing-job-jwj9x launched.\n",
      "[W 201206 10:57:15 manager:298] Waiting for fairing-job-jwj9x-ljzjb to start...\n",
      "[W 201206 10:57:15 manager:298] Waiting for fairing-job-jwj9x-ljzjb to start...\n",
      "[W 201206 10:57:33 manager:298] Waiting for fairing-job-jwj9x-ljzjb to start...\n",
      "[W 201206 10:57:33 manager:298] Waiting for fairing-job-jwj9x-ljzjb to start...\n",
      "[I 201206 10:57:35 manager:304] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-06 10:57:37.554405: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-12-06 10:57:37.554630: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-12-06 10:57:37.554656: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "2020-12-06 10:57:39.870979: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-12-06 10:57:39.871066: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-12-06 10:57:39.871098: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fairing-job-jwj9x-ljzjb): /proc/driver/nvidia/version does not exist\n",
      "2020-12-06 10:57:39.871343: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-12-06 10:57:39.880939: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
      "2020-12-06 10:57:39.881585: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a10d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-06 10:57:39.881636: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #\n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0\n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480\n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290\n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      " 1344/48000 [..............................] - ETA: 27s - loss: 1.4341 - accuracy: 0.59395\n",
      " 3392/48000 [=>............................] - ETA: 16s - loss: 0.9618 - accuracy: 0.712\n",
      " 5888/48000 [==>...........................] - ETA: 13s - loss: 0.7790 - accuracy: 0.778\n",
      " 7904/48000 [===>..........................] - ETA: 12s - loss: 0.6591 - accuracy: 0.817\n",
      "10016/48000 [=====>........................] - ETA: 10s - loss: 0.5982 - accuracy: 0.825\n",
      "12160/48000 [======>.......................] - ETA: 10s - loss: 0.5615 - accuracy: 0.838\n",
      "14592/48000 [=======>......................] - ETA: 9s - loss: 0.5178 - accuracy: 0.85\n",
      "16352/48000 [=========>....................] - ETA: 8s - loss: 0.4960 - accuracy: 0.857\n",
      "18464/48000 [==========>...................] - ETA: 7s - loss: 0.4730 - accuracy: 0.864\n",
      "20928/48000 [============>.................] - ETA: 7s - loss: 0.4502 - accuracy: 0.86\n",
      "23456/48000 [=============>................] - ETA: 6s - loss: 0.4366 - accuracy: 0.87\n",
      "25504/48000 [==============>...............] - ETA: 5s - loss: 0.4189 - accuracy: 0.87\n",
      "26784/48000 [===============>..............] - ETA: 5s - loss: 0.4121 - accuracy: 0.88\n",
      "29152/48000 [=================>............] - ETA: 4s - loss: 0.3988 - accuracy: 0.88\n",
      "31680/48000 [==================>...........] - ETA: 4s - loss: 0.3876 - accuracy: 0.88\n",
      "34208/48000 [====================>.........] - ETA: 3s - loss: 0.3765 - accuracy: 0.89\n",
      "36320/48000 [=====================>........] - ETA: 2s - loss: 0.3662 - accuracy: 0.893\n",
      "38784/48000 [=======================>......] - ETA: 2s - loss: 0.3572 - accuracy: 0.896\n",
      "40832/48000 [========================>.....] - ETA: 1s - loss: 0.3507 - accuracy: 0.89\n",
      "42880/48000 [=========================>....] - ETA: 1s - loss: 0.3443 - accuracy: 0.89\n",
      "44928/48000 [==========================>...] - ETA: 0s - loss: 0.3381 - accuracy: 0.90\n",
      "46912/48000 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.90\n",
      "48000/48000 [==============================] - 14s 288us/sample - loss: 0.3296 - accuracy: 0.9044 - val_loss: 0.1608 - val_accuracy: 0.9544\n",
      "Epoch 2/3\n",
      "  992/48000 [..............................] - ETA: 12s - loss: 0.1810 - accuracy: 0.952\n",
      " 3264/48000 [=>............................] - ETA: 11s - loss: 0.1808 - accuracy: 0.948\n",
      " 4928/48000 [==>...........................] - ETA: 10s - loss: 0.1807 - accuracy: 0.948\n",
      " 7008/48000 [===>..........................] - ETA: 10s - loss: 0.1826 - accuracy: 0.949\n",
      " 9504/48000 [====>.........................] - ETA: 9s - loss: 0.1811 - accuracy: 0.9488\n",
      "11968/48000 [======>.......................] - ETA: 8s - loss: 0.1826 - accuracy: 0.94\n",
      "14016/48000 [=======>......................] - ETA: 8s - loss: 0.1832 - accuracy: 0.94\n",
      "16096/48000 [=========>....................] - ETA: 7s - loss: 0.1790 - accuracy: 0.94\n",
      "18624/48000 [==========>...................] - ETA: 7s - loss: 0.1799 - accuracy: 0.948\n",
      "20608/48000 [===========>..................] - ETA: 6s - loss: 0.1785 - accuracy: 0.948\n",
      "22400/48000 [=============>................] - ETA: 6s - loss: 0.1774 - accuracy: 0.94\n",
      "24864/48000 [==============>...............] - ETA: 5s - loss: 0.1770 - accuracy: 0.94\n",
      "26528/48000 [===============>..............] - ETA: 5s - loss: 0.1774 - accuracy: 0.94\n",
      "28480/48000 [================>.............] - ETA: 4s - loss: 0.1755 - accuracy: 0.94\n",
      "29856/48000 [=================>............] - ETA: 4s - loss: 0.1742 - accuracy: 0.9494\n",
      "32128/48000 [===================>..........] - ETA: 4s - loss: 0.1721 - accuracy: 0.94\n",
      "34496/48000 [====================>.........] - ETA: 3s - loss: 0.1708 - accuracy: 0.95\n",
      "35968/48000 [=====================>........] - ETA: 2s - loss: 0.1683 - accuracy: 0.950\n",
      "37600/48000 [======================>.......] - ETA: 2s - loss: 0.1676 - accuracy: 0.951\n",
      "39744/48000 [=======================>......] - ETA: 2s - loss: 0.1660 - accuracy: 0.95\n",
      "41792/48000 [=========================>....] - ETA: 1s - loss: 0.1640 - accuracy: 0.95\n",
      "43456/48000 [==========================>...] - ETA: 1s - loss: 0.1624 - accuracy: 0.95\n",
      "45184/48000 [===========================>..] - ETA: 0s - loss: 0.1613 - accuracy: 0.95\n",
      "47712/48000 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.95\n",
      "48000/48000 [==============================] - 13s 277us/sample - loss: 0.1602 - accuracy: 0.9534 - val_loss: 0.1175 - val_accuracy: 0.9654\n",
      "Epoch 3/3\n",
      " 1760/48000 [>.............................] - ETA: 12s - loss: 0.1184 - accuracy: 0.965\n",
      " 3840/48000 [=>............................] - ETA: 11s - loss: 0.1119 - accuracy: 0.966\n",
      " 6176/48000 [==>...........................] - ETA: 10s - loss: 0.1112 - accuracy: 0.967\n",
      " 7520/48000 [===>..........................] - ETA: 10s - loss: 0.1108 - accuracy: 0.966\n",
      " 9248/48000 [====>.........................] - ETA: 9s - loss: 0.1143 - accuracy: 0.964\n",
      "11008/48000 [=====>........................] - ETA: 8s - loss: 0.1165 - accuracy: 0.96\n",
      "13120/48000 [=======>......................] - ETA: 8s - loss: 0.1175 - accuracy: 0.96\n",
      "14688/48000 [=======>......................] - ETA: 8s - loss: 0.1177 - accuracy: 0.96\n",
      "15808/48000 [========>.....................] - ETA: 7s - loss: 0.1188 - accuracy: 0.96\n",
      "17792/48000 [==========>...................] - ETA: 7s - loss: 0.1176 - accuracy: 0.96\n",
      "20224/48000 [===========>..................] - ETA: 6s - loss: 0.1170 - accuracy: 0.96\n",
      "22688/48000 [=============>................] - ETA: 6s - loss: 0.1175 - accuracy: 0.96\n",
      "24736/48000 [==============>...............] - ETA: 5s - loss: 0.1187 - accuracy: 0.965\n",
      "26464/48000 [===============>..............] - ETA: 5s - loss: 0.1186 - accuracy: 0.965\n",
      "28032/48000 [================>.............] - ETA: 4s - loss: 0.1184 - accuracy: 0.964\n",
      "29632/48000 [=================>............] - ETA: 4s - loss: 0.1185 - accuracy: 0.96\n",
      "31360/48000 [==================>...........] - ETA: 4s - loss: 0.1175 - accuracy: 0.96\n",
      "32544/48000 [===================>..........] - ETA: 3s - loss: 0.1170 - accuracy: 0.96\n",
      "34432/48000 [====================>.........] - ETA: 3s - loss: 0.1190 - accuracy: 0.96\n",
      "36544/48000 [=====================>........] - ETA: 2s - loss: 0.1178 - accuracy: 0.96\n",
      "39008/48000 [=======================>......] - ETA: 2s - loss: 0.1180 - accuracy: 0.96\n",
      "41054/48000 [========================>.....] - ETA: 1s - loss: 0.1177 - accuracy: 0.96\n",
      "43136/48000 [=========================>....] - ETA: 1s - loss: 0.1175 - accuracy: 0.965\n",
      "44800/48000 [===========================>..] - ETA: 0s - loss: 0.1171 - accuracy: 0.965\n",
      "46976/48000 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.96\n",
      "48000/48000 [==============================] - 13s 276us/sample - loss: 0.1164 - accuracy: 0.9656 - val_loss: 0.0965 - val_accuracy: 0.9712\n",
      "Test accuracy:  0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 201206 10:58:22 job:173] Cleaning up job fairing-job-jwj9x...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<kubeflow.fairing.preprocessors.base.BasePreProcessor at 0x7f2d342e3400>,\n",
       " <kubeflow.fairing.builders.append.append.AppendBuilder at 0x7f2d342e34a8>,\n",
       " <kubeflow.fairing.deployers.job.job.Job at 0x7f2d342e3438>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kubeflow import fairing\n",
    "from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "\n",
    "PRIVATE_REGISTRY = 'kubeflow-registry.default.svc.cluster.local:30000'\n",
    "\n",
    "fairing.config.set_preprocessor(\n",
    "    'python', \n",
    "     # command = ['python'],  # default: python\n",
    "     input_files = ['00-python-file-to-fairing.py'],     \n",
    ")\n",
    "\n",
    "fairing.config.set_builder(\n",
    "    'append',\n",
    "    base_image = f'{PRIVATE_REGISTRY}/kf-base:latest', # 사전준비에서 마련한 Base Image\n",
    "    registry = PRIVATE_REGISTRY,\n",
    "    image_name='my-02-python-file-fairing', \n",
    "    push=True\n",
    ")\n",
    "\n",
    "fairing.config.set_deployer(\n",
    "    'job',\n",
    "    namespace='myspace',\n",
    "    pod_spec_mutators=[\n",
    "        k8s_utils.get_resource_mutator(cpu=1, memory=5)]\n",
    ")\n",
    "\n",
    "fairing.config.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "reddiana/jupyterlab-kale:0.0.9",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
