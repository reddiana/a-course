{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "class MyFashionMnist(object):\n",
    "  def train(self):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    model.fit(\n",
    "        x_train, y_train, \n",
    "        epochs=3, \n",
    "        validation_split=0.2 \n",
    "    ) \n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, batch_size=128, verbose=0)\n",
    "    print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 201207 00:52:36 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7f7ef00931d0>\n",
      "[I 201207 00:52:36 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f7e426979e8>\n",
      "[I 201207 00:52:36 config:138] Using deployer: <kubeflow.fairing.deployers.job.job.Job object at 0x7f7e332d7d30>\n",
      "[W 201207 00:52:36 append:50] Building image using Append builder...\n",
      "[I 201207 00:52:36 base:107] Creating docker context: /tmp/fairing_context_n0fj8bj1\n",
      "[I 201207 00:52:36 converted_notebook:127] Converting 04-notebook-single-file-fairing.ipynb to 04-notebook-single-file-fairing.py\n",
      "[I 201207 00:52:36 docker_creds_:234] Loading Docker credentials for repository 'kubeflow-registry.default.svc.cluster.local:30000/kf-base:latest'\n",
      "[W 201207 00:52:36 append:54] Image successfully built in 0.14476266099973145s.\n",
      "[W 201207 00:52:36 append:94] Pushing image kubeflow-registry.default.svc.cluster.local:30000/my-04-notebook-single-file-fairing-job:848100A8...\n",
      "[I 201207 00:52:36 docker_creds_:234] Loading Docker credentials for repository 'kubeflow-registry.default.svc.cluster.local:30000/my-04-notebook-single-file-fairing-job:848100A8'\n",
      "[W 201207 00:52:36 append:81] Uploading kubeflow-registry.default.svc.cluster.local:30000/my-04-notebook-single-file-fairing-job:848100A8\n",
      "[I 201207 00:52:36 docker_session_:284] Layer sha256:4c1d20cdee96111c8acf1858b62655a37ce81ae48648993542b7ac363ac5c0e5 pushed.\n",
      "[I 201207 00:52:36 docker_session_:284] Layer sha256:8592f093fc78e0d933851ed625592627241c475dd46adad77f37dec9cc867446 pushed.\n",
      "[I 201207 00:52:36 docker_session_:284] Layer sha256:0d3160e1d0de4061b5b32ee09af687b898921d36ed9556df5910ddc3104449cd pushed.\n",
      "[I 201207 00:52:36 docker_session_:284] Layer sha256:c8e37668deea784f47c8726d934adc12b8d20a2b1c50b0b0c18cb62771cd3684 pushed.\n",
      "[I 201207 00:52:36 docker_session_:284] Layer sha256:107f0b841886b4e032a6ced874db81b71dcdc5e6827b6c0d195defe4c6e661da pushed.\n",
      "[I 201207 00:52:36 docker_session_:284] Layer sha256:edc69fe5c6be6938f490e5f91cdb6369799b4a509fd72c292e0cd6fdb3c345b3 pushed.\n",
      "[I 201207 00:52:37 docker_session_:284] Layer sha256:75c61371a2e390c1d05234b28163580c90c2e26c6d245984a4da73f9f022c102 pushed.\n",
      "[I 201207 00:52:37 docker_session_:284] Layer sha256:fd61cc3a806e03543f14c18e5b748620a2ec7d89fc0855effab549e09f7a0c32 pushed.\n",
      "[I 201207 00:52:37 docker_session_:284] Layer sha256:c9f7a8e0642e99226dbb089a460679315c24814fb14b67dc6a7df466c75bcc8f pushed.\n",
      "[I 201207 00:52:37 docker_session_:284] Layer sha256:2746a4a261c9e18bfd7ff0429c18fd7522acc14fa4c7ec8ab37ba5ebaadbc584 pushed.\n",
      "[I 201207 00:52:37 docker_session_:284] Layer sha256:e52cad4ccd832fc331516c5a5632fdd08c37d711ff243c7e04d6e8c374b9c474 pushed.\n",
      "[I 201207 00:52:42 docker_session_:284] Layer sha256:4d220205e6561101f16a16ded38672d66c0c0eb0c7c03ae4d3453e534ccbba5d pushed.\n",
      "[I 201207 00:52:42 docker_session_:284] Layer sha256:9fcc87d7457ee5fe12204e9c224603d53519a444aa258c67b63db2b33884cccf pushed.\n",
      "[I 201207 00:52:42 docker_session_:284] Layer sha256:e97116da5f9876a95d0d3f0fd1e3bcc48721f9ac6351ce23aaa3d261b4f9b0d6 pushed.\n",
      "[I 201207 00:52:56 docker_session_:284] Layer sha256:dccb0709d7fb37e513a933c3848be077f0e514e41a084bd9f3f27dcde169ae20 pushed.\n",
      "[I 201207 00:52:56 docker_session_:334] Finished upload of: kubeflow-registry.default.svc.cluster.local:30000/my-04-notebook-single-file-fairing-job:848100A8\n",
      "[W 201207 00:52:56 append:99] Pushed image kubeflow-registry.default.svc.cluster.local:30000/my-04-notebook-single-file-fairing-job:848100A8 in 19.429596773000412s.\n",
      "[W 201207 00:52:56 job:101] The job fairing-job-q6nlt launched.\n",
      "[W 201207 00:52:56 manager:298] Waiting for fairing-job-q6nlt-wbrtq to start...\n",
      "[W 201207 00:52:56 manager:298] Waiting for fairing-job-q6nlt-wbrtq to start...\n",
      "[W 201207 00:52:56 manager:298] Waiting for fairing-job-q6nlt-wbrtq to start...\n",
      "[I 201207 00:52:58 manager:304] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-07 00:53:00.941274: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-12-07 00:53:00.941458: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-12-07 00:53:00.941500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "2020-12-07 00:53:02.662149: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-12-07 00:53:02.662191: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-12-07 00:53:02.662214: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fairing-job-q6nlt-wbrtq): /proc/driver/nvidia/version does not exist\n",
      "2020-12-07 00:53:02.662519: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-12-07 00:53:02.671562: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
      "2020-12-07 00:53:02.672184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4560ab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-07 00:53:02.672221: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-12-07 00:53:02.793936: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 301056000 exceeds 10% of system memory.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #\n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0\n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480\n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290\n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      " 1920/48000 [>.............................] - ETA: 17s - loss: 1.2670 - accuracy: 0.6277\n",
      " 4128/48000 [=>............................] - ETA: 13s - loss: 0.9090 - accuracy: 0.721\n",
      " 6912/48000 [===>..........................] - ETA: 11s - loss: 0.7431 - accuracy: 0.785\n",
      " 9216/48000 [====>.........................] - ETA: 10s - loss: 0.6242 - accuracy: 0.820\n",
      "11584/48000 [======>.......................] - ETA: 9s - loss: 0.5711 - accuracy: 0.835\n",
      "14272/48000 [=======>......................] - ETA: 8s - loss: 0.5248 - accuracy: 0.84\n",
      "16960/48000 [=========>....................] - ETA: 7s - loss: 0.4968 - accuracy: 0.85\n",
      "19232/48000 [===========>..................] - ETA: 6s - loss: 0.4667 - accuracy: 0.86\n",
      "21792/48000 [============>.................] - ETA: 6s - loss: 0.4453 - accuracy: 0.87\n",
      "24544/48000 [==============>...............] - ETA: 5s - loss: 0.4247 - accuracy: 0.87\n",
      "27264/48000 [================>.............] - ETA: 4s - loss: 0.4102 - accuracy: 0.88\n",
      "29920/48000 [=================>............] - ETA: 4s - loss: 0.3946 - accuracy: 0.88\n",
      "32192/48000 [===================>..........] - ETA: 3s - loss: 0.3797 - accuracy: 0.891\n",
      "35008/48000 [====================>.........] - ETA: 2s - loss: 0.3681 - accuracy: 0.895\n",
      "37664/48000 [======================>.......] - ETA: 2s - loss: 0.3580 - accuracy: 0.89\n",
      "40480/48000 [========================>.....] - ETA: 1s - loss: 0.3501 - accuracy: 0.90\n",
      "43104/48000 [=========================>....] - ETA: 1s - loss: 0.3421 - accuracy: 0.90\n",
      "45312/48000 [===========================>..] - ETA: 0s - loss: 0.3338 - accuracy: 0.90\n",
      "48000/48000 [==============================] - 13s 261us/sample - loss: 0.3265 - accuracy: 0.9068 - val_loss:\n",
      "0.1581 - val_accuracy: 0.9565\n",
      "Epoch 2/3\n",
      " 1952/48000 [>.............................] - ETA: 11s - loss: 0.1593 - accuracy: 0.949\n",
      " 4640/48000 [=>............................] - ETA: 10s - loss: 0.1646 - accuracy: 0.947\n",
      " 7360/48000 [===>..........................] - ETA: 9s - loss: 0.1599 - accuracy: 0.959\n",
      "19600/48000 [=====>........................] - ETA: 8s - loss: 0.1621 - accuracy: 0.95\n",
      "12288/48000 [======>.......................] - ETA: 7s - loss: 0.1597 - accuracy: 0.95\n",
      "14624/48000 [========>.....................] - ETA: 7s - loss: 0.1616 - accuracy: 0.95\n",
      "17280/48000 [=========>....................] - ETA: 6s - loss: 0.1603 - accuracy: 0.95\n",
      "20032/48000 [===========>..................] - ETA: 6s - loss: 0.1595 - accuracy: 0.95\n",
      "22176/48000 [============>.................] - ETA: 5s - loss: 0.1607 - accuracy: 0.951\n",
      "24928/48000 [==============>...............] - ETA: 5s - loss: 0.1598 - accuracy: 0.952\n",
      "27712/48000 [================>.............] - ETA: 4s - loss: 0.1600 - accuracy: 0.951\n",
      "30624/48000 [==================>...........] - ETA: 3s - loss: 0.1593 - accuracy: 0.95\n",
      "33344/48000 [===================>..........] - ETA: 3s - loss: 0.1579 - accuracy: 0.95\n",
      "35552/48000 [=====================>........] - ETA: 2s - loss: 0.1566 - accuracy: 0.95\n",
      "38304/48000 [======================>.......] - ETA: 2s - loss: 0.1569 - accuracy: 0.95\n",
      "40992/48000 [========================>.....] - ETA: 1s - loss: 0.1564 - accuracy: 0.95\n",
      "43744/48000 [==========================>...] - ETA: 1s - loss: 0.1556 - accuracy: 0.95\n",
      "45952/48000 [===========================>..] - ETA: 0s - loss: 0.1549 - accuracy: 0.95\n",
      "48000/48000 [==============================] - 12s 250us/sample - loss: 0.1549 - accuracy: 0.9537 - val_loss: 0.1131 - val_accuracy: 0.9673\n",
      "Epoch 3/3\n",
      " 1888/48000 [>.............................] - ETA: 11s - loss: 0.1222 - accuracy: 0.965\n",
      " 4544/48000 [=>............................] - ETA: 10s - loss: 0.1117 - accuracy: 0.966\n",
      " 7104/48000 [===>..........................] - ETA: 9s - loss: 0.1121 - accuracy: 0.9688\n",
      " 9344/48000 [====>.........................] - ETA: 8s - loss: 0.1111 - accuracy: 0.96\n",
      "11968/48000 [======>.......................] - ETA: 8s - loss: 0.1140 - accuracy: 0.96\n",
      "14656/48000 [========>.....................] - ETA: 7s - loss: 0.1141 - accuracy: 0.96\n",
      "17376/48000 [=========>....................] - ETA: 6s - loss: 0.1167 - accuracy: 0.96\n",
      "19680/48000 [===========>..................] - ETA: 6s - loss: 0.1158 - accuracy: 0.96\n",
      "22048/48000 [============>.................] - ETA: 5s - loss: 0.1159 - accuracy: 0.965\n",
      "24704/48000 [==============>...............] - ETA: 5s - loss: 0.1153 - accuracy: 0.965\n",
      "27424/48000 [================>.............] - ETA: 4s - loss: 0.1145 - accuracy: 0.96\n",
      "30144/48000 [=================>............] - ETA: 4s - loss: 0.1142 - accuracy: 0.96\n",
      "32800/48000 [===================>..........] - ETA: 3s - loss: 0.1140 - accuracy: 0.96\n",
      "34976/48000 [====================>.........] - ETA: 2s - loss: 0.1133 - accuracy: 0.96\n",
      "37696/48000 [======================>.......] - ETA: 2s - loss: 0.1127 - accuracy: 0.96\n",
      "40416/48000 [========================>.....] - ETA: 1s - loss: 0.1136 - accuracy: 0.96\n",
      "43168/48000 [=========================>....] - ETA: 1s - loss: 0.1130 - accuracy: 0.96\n",
      "45376/48000 [===========================>..] - ETA: 0s - loss: 0.1139 - accuracy: 0.966\n",
      "47712/48000 [============================>.] - ETA: 0s - loss: 0.1138 - accuracy: 0.966\n",
      "48000/48000 [==============================] - 12s 256us/sample - loss: 0.1137 - accuracy: 0.9662 - val_loss: 0.1018 - val_accuracy: 0.9693\n",
      "Test accuracy:  0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 201207 00:53:41 job:173] Cleaning up job fairing-job-q6nlt...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        from kubeflow import fairing\n",
    "        from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "        \n",
    "        PRIVATE_REGISTRY = 'kubeflow-registry.default.svc.cluster.local:30000'\n",
    "        \n",
    "        # fairing.config.set_preprocessor(\n",
    "        #     'notebook', \n",
    "        #     command = ['python3'],  # default: python\n",
    "        # )\n",
    "        \n",
    "        fairing.config.set_builder(\n",
    "            'append',\n",
    "            base_image=f'{PRIVATE_REGISTRY}/kf-base:latest', # 사전준비에서 마련한 Base Image\n",
    "            registry = PRIVATE_REGISTRY,\n",
    "            image_name='my-04-notebook-single-file-fairing-job', \n",
    "            push=True\n",
    "        )\n",
    "        \n",
    "        fairing.config.set_deployer(\n",
    "            'job',\n",
    "            namespace='myspace',\n",
    "            pod_spec_mutators=[\n",
    "                k8s_utils.get_resource_mutator(cpu=1, memory=5)]\n",
    "        )\n",
    "        \n",
    "        fairing.config.run()\n",
    "    else:\n",
    "        remote_train = MyFashionMnist()\n",
    "        remote_train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "reddiana/jupyterlab-kale:0.0.9",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
