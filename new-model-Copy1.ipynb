{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers, models, layers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from minio.error import ResponseError\n",
    "\n",
    "minioClient = Minio(\n",
    "                'minio-service.kubeflow:9000',\n",
    "                access_key='minio', \n",
    "                secret_key='minio123', \n",
    "                secure=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-05  #1e-05  # This value is specific to what model is chosen: Inception, VGG or ResnNet.\n",
    "EPOCHS = 30 \n",
    "BS = 8\n",
    "\n",
    "print(\"Loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ...  227 images loaded in 3x classes:\n",
      "['covid' 'normal' 'pneumonia_bac']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# read all X-Rays in the specified path, and resize them all to 256x256\n",
    "\n",
    "for i in minioClient.list_objects('dataset', prefix='covid-19', recursive=True):\n",
    "    label = i.object_name.split(os.path.sep)[-2]\n",
    "\n",
    "    minioObj = minioClient.get_object('dataset', i.object_name)\n",
    "    byteArray = minioObj.read()\n",
    "    pil_image = Image.open(io.BytesIO(byteArray)).convert('RGB')\n",
    "    image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "    \n",
    "#normalise pixel values to real numbers between 0.0 - 1.0 \n",
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding for a 3-class labeling \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "labels = to_categorical(integer_encoded)\n",
    "\n",
    "print(\"... ... \", len(data), \"images loaded in 3x classes:\")\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, x_val, y_train, y_val) = train_test_split(data, labels, test_size=0.20, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.00001 # List: 0.001, 0.0001, 0.0003, 0.00001, 0.00003\n",
    "DENSE = 128             # Range: 50-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Model)           (None, 8, 8, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16777344  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 40,367,235\n",
      "Trainable params: 16,798,339\n",
      "Non-trainable params: 23,568,896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "adam_s = Adam(learning_rate = LEARNING_RATE)\n",
    "\n",
    "#model.add(VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet', pooling='average'))\n",
    "model.add(ResNet50V2(input_shape=(256, 256, 3),include_top=False, weights='imagenet',pooling='average'))\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(DENSE, activation='relu'))\n",
    "model.add(Dense(DENSE, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam_s, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the full stack model...\n",
      "Train on 181 samples, validate on 46 samples\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 21s 117ms/sample - loss: 0.8518 - accuracy: 0.5856 - val_loss: 1.3832 - val_accuracy: 0.4783\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 18s 98ms/sample - loss: 0.2696 - accuracy: 0.9503 - val_loss: 1.0109 - val_accuracy: 0.5870\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 18s 97ms/sample - loss: 0.1374 - accuracy: 0.9669 - val_loss: 0.8313 - val_accuracy: 0.6304\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 18s 97ms/sample - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.6957\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 17s 96ms/sample - loss: 0.0646 - accuracy: 0.9890 - val_loss: 0.5718 - val_accuracy: 0.8261\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 17s 97ms/sample - loss: 0.0342 - accuracy: 0.9945 - val_loss: 0.5134 - val_accuracy: 0.8696\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 17s 96ms/sample - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8696\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 18s 98ms/sample - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.8913\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 17s 96ms/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.8261\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 17s 94ms/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.8478\n"
     ]
    }
   ],
   "source": [
    "# train the head of the network\n",
    "print(\"Training the full stack model...\")\n",
    "H = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val), batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "# model.save('resnet50.h5')\n",
    "# new_model = tensorflow.keras.models.load_model('resnet50.h5')\n",
    "\n",
    "# model.save('new-covid/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s3://model/new-covid/1/assets\n"
     ]
    }
   ],
   "source": [
    "os.environ.update({\n",
    "    'S3_ENDPOINT'          : 'minio-service.kubeflow:9000',\n",
    "    'AWS_ACCESS_KEY_ID'    : 'minio',\n",
    "    'AWS_SECRET_ACCESS_KEY': 'minio123',\n",
    "    'S3_USE_HTTPS'         : '0',\t# Whether or not to use HTTPS. Disable with 0.                        \n",
    "    'S3_VERIFY_SSL'        : '0' \t# If HTTPS is used, controls if SSL should be enabled. Disable with 0.\n",
    "})  \n",
    "\n",
    "model.save(\"s3://model/new-covid/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading untrained test images...\n",
      "27\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading untrained test images...\")\n",
    "imagePathTest = \"./all/test\"\n",
    "imagePathsTest = list(paths.list_images(imagePathTest))\n",
    "print(len(imagePathsTest))\n",
    "\n",
    "dataTest = []\n",
    "labelsTest = []\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePathTest in imagePathsTest:\n",
    "\n",
    "    # extract the class label from the filename\n",
    "\t  labelTest = imagePathTest.split(os.path.sep)[-2]\n",
    "  \n",
    "\t  # load the image, swap color channels, and resize it to be a fixed\n",
    "\t  # 256x256 pixels while ignoring aspect ratio\n",
    "\t  imageTest = cv2.imread(imagePathTest)\n",
    "\t  imageTest = cv2.cvtColor(imageTest, cv2.COLOR_BGR2RGB)\n",
    "\t  imageTest = cv2.resize(imageTest, (256, 256))\n",
    "\n",
    "\t  # update the data and labels lists, respectively\n",
    "\t  dataTest.append(imageTest)\n",
    "\t  labelsTest.append(labelTest)\n",
    "# convert the data and labels to NumPy arrays while scaling the pixel\n",
    "# intensities to the range [0, 255]\n",
    "dataTest = np.array(dataTest) / 255.0\n",
    "labelsTest = np.array(labelsTest)\n",
    "\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labelsTest)\n",
    "labelsTest = to_categorical(integer_encoded)\n",
    "\n",
    "print(labelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0068557  0.02678966 0.96635467]\n",
      " [0.03875601 0.12253342 0.8387106 ]\n",
      " [0.01659377 0.42695478 0.55645144]\n",
      " [0.02627762 0.1159509  0.8577715 ]\n",
      " [0.00122558 0.00290923 0.9958652 ]\n",
      " [0.11798634 0.11365311 0.76836056]\n",
      " [0.00595036 0.00327872 0.99077094]\n",
      " [0.02789457 0.31944716 0.6526582 ]\n",
      " [0.00161389 0.00217918 0.9962069 ]\n",
      " [0.78979254 0.01098451 0.19922292]\n",
      " [0.2622419  0.1425396  0.5952185 ]\n",
      " [0.45421702 0.06200984 0.48377308]\n",
      " [0.4373251  0.01652702 0.5461478 ]\n",
      " [0.88145435 0.01188093 0.1066647 ]\n",
      " [0.9562477  0.00784262 0.03590965]\n",
      " [0.83745414 0.02574706 0.13679886]\n",
      " [0.48259628 0.08266492 0.43473884]\n",
      " [0.4833918  0.13619097 0.3804173 ]\n",
      " [0.00976312 0.92319435 0.06704257]\n",
      " [0.0161733  0.4871007  0.49672604]\n",
      " [0.01608484 0.58128566 0.40262946]\n",
      " [0.01657279 0.8673781  0.11604912]\n",
      " [0.02541882 0.61463773 0.35994342]\n",
      " [0.01231234 0.40142035 0.5862673 ]\n",
      " [0.015098   0.23081088 0.7540911 ]\n",
      " [0.00716045 0.91683143 0.0760081 ]\n",
      " [0.03639211 0.79298884 0.17061903]]\n"
     ]
    }
   ],
   "source": [
    "predTest = model.predict(dataTest, batch_size=BS)\n",
    "print(predTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 0 2 2 2 0 0 0 0 0 1 2 1 1 1 2 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "predClasses = predTest.argmax(axis=-1)\n",
    "print(predClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://35.206.247.237:32380/v1/models/covid19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "import cv2\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#get some sample data\n",
    "sample_test_data = dataTest  #[0:2]\n",
    "sample_test_labels = labelsTest #[0:2]\n",
    "\n",
    "print(sample_test_data.shape)\n",
    "\n",
    "class_names = ['covid', 'normal', 'pneumonia_bac']\n",
    "\n",
    "# pre-process data \n",
    "#sample_test_data_processed = np.expand_dims(sample_test_data / 255., axis=3)\n",
    "\n",
    "sample_test_data_processed = sample_test_data\n",
    "\n",
    "# create payload\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \n",
    "                   \"instances\": sample_test_data_processed.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"image_data.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -v -H \"Host: covid19.kubeflow.example.com\" -X POST http://35.206.247.237:32380/v1/models/covid19:predict -d@image_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {'content-type': 'application/json'}\n",
    "#MODEL1_API_URL = 'http://172.17.0.1:8511/v1/models/covid19/versions/2:predict'\n",
    "MODEL1_API_URL = 'http://35.206.247.237:32380/v1/models/covid19:predict'\n",
    "\n",
    "# inference request\n",
    "json_response = requests.post(MODEL1_API_URL, data=data, headers=HEADERS)\n",
    "\n",
    "print(json_response)\n",
    "\n",
    "pred = json.loads(json_response.content.decode('utf-8'))\n",
    "print(pred)\n",
    "\n",
    "# view server response\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "predictions = np.argmax(np.array(predictions), axis=1)\n",
    "prediction_labels = [class_names[p] for p in predictions]\n",
    "\n",
    "fig, ax = plt.subplots(6, 5, figsize=(60, 80))\n",
    "for idx, img in enumerate(sample_test_data):\n",
    "    rowidx = idx // 5\n",
    "    colidx = idx % 5\n",
    "    ax[rowidx, colidx].imshow(img)\n",
    "    ax[rowidx, colidx].set_title('Actual: {}\\nPredicted: {}'.format(class_names[sample_test_labels[idx].argmax(axis=-1)], \n",
    "                                                                    prediction_labels[idx]), fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "reddiana/jupyterlab-kale:latest",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
